<!doctype html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="google-site-verification" content="aIiuTLs4iiznZTMM51mRInTWsOjHw3RKrXQ_nsBFzz8" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/css/bootstrap.min.css"
        integrity="sha384-B0vP5xmATw1+K9KRQjQERJvTumQW0nPEzvF6L/Z6nronJ3oUOFUFpCjEUQouq2+l" crossorigin="anonymous">
    <link rel="stylesheet" href="./bootstrap_5.0.2_range.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <script src="https://code.jquery.com/jquery-3.3.1.min.js" type="text/javascript"></script>


    <title>Neural Caches for Monte Carlo Partial Differential Equation Solver
        </title>
</head>

<body class="container" style="max-width:900px">

    <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js"
        integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj"
        crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/js/bootstrap.bundle.min.js"
        integrity="sha384-Piv4xVNRyMGpqkS2by6br4gNJ7DXjqk09RmUpJ8jgGtD7zP9yug3goQfGII0yAns"
        crossorigin="anonymous"></script>

    <!-- heading -->
    <div>
        <!-- title -->
        <div class='row mt-5 mb-3'>
            <div class='col text-center'>
                <p class="h2 font-weight-normal">Neural Caches for Monte Carlo Partial Differential Equation Solver</p>
            </div>
        </div>

        <!-- authors -->
        <div class="col text-center h6 font-weight-bold mb-2 ">
            <span class="col-md-1" style="flex: 0 0 25%; max-width: 25%;"></span>
            <span><a class="col-md-4 col-xs-6 pb-2" href="https://zilulii.github.io"><span>Zilu Li*</span></a>
            <span><a class="col-md-4 col-xs-6 pb-2" href="http://www.guandaoyang.com"><span>Guandao Yang*</span></a>
            <span><a class="col-md-4 col-xs-6 pb-2" href="https://www.cs.cornell.edu/~xideng/"><span>Xi Deng</span></a>
        </div>
        <div class="col text-center h6 font-weight-bold mb-3">
            <span class="col-md-1" style="flex: 0 0 25%; max-width: 25%;"></span>
            <span><a class="col-md-4 col-xs-6 pb-2" href="https://www.cs.cornell.edu/~cdesa/"><span>Chris De Sa</span></a>
            <span><a class="col-md-4 col-xs-6 pb-2" href="https://www.cs.cornell.edu/~bharathh/"><span>Bharath Hariharan</span></a>
            <span><a class="col-md-4 col-xs-6 pb-2" href="https://www.cs.cornell.edu/~srm/"><span>Steve Marschner</span></a>
        </div>
        <!-- affiliations -->
        <div class="row mb-1">
            <div class="col text-center">
                <p class="h6">
                    <span class="col-md-4">Cornell University</span>
                </p>
            </div>
        </div>

        <!-- venue -->
        <div class='row mb-2'>
            <div class='col text-center'>
                <p class="h6"> SIGGRAPH Asia 2023 (Conference)
                </p>
            </div>
        </div>

        <!-- links -->
        <div class='row mb-4'>
            <div class='col text-center'>
                <a href="assets/SA23_upload.pdf" class="btn btn-outline-primary" role="button">
                    <i class="ai ai-arxiv"></i>
                    Paper
                </a>
                <a href="https://github.com/ZiluLii/NeuralCache" class="btn btn-outline-primary" role="button">
                    <i class="fa fa-github"></i>
                    Code
                </a>
            </div>
        </div>
    </div>

    <!-- teaser -->
    <div class='row justify-content-center'>

        <div class='col-md-12 col-sm-12 col-xs-12 align-middle mt-4'>
            <p class='h5'>
                We combine Neural Field with Monte Carlo method, provide a faster and more accurate PDE solver.
            </p>
        </div>
    </div>
    <br>
    <div class="card">
        <img src="assets/mcgpnf_teaser.png" class="img-fluid rounded mx-auto d-block">
        <p style="margin: 10px; margin-bottom: 4px;">
            We visualize a slice of the solution to an elliptic PDE within a dragon-shaped boundary. 
            Our hybrid solver can reduce the error of the neural field baseline, 
            while achieving lower variance compared to the Walk-on-Spheres <a href="http://www.rohansawhney.io/vcwos.pdf">(VCWoS)</a>
            method when working within the constraints of a limited computing budget
        </p>
    </div>


    <!-- Paper section -->
    <div>
        <!-- <hr> -->
        <div class="row">
            <div class='col-md-3 col-sm-3 col-xs-12 text-center my-auto'>
                <div class="row">
                    <a href="assets/SA23_upload.pdf" style="max-width:200px;"><!-- pdf link -->
                        <img src="assets/paper-snapshot.png" alt="paper-snapshot" class="img-thumbnail" height="75%"
                            style="box-shadow: 10px 10px 5px grey;">
                    </a>
                </div>
            </div>
            <div class='col-md-9 col-sm-9 col-xs-12'>
                <p class='h4 font-weight-bold' style="margin-top: 5px;">Abstract</p>
                <p> This paper presents a method that uses neural networks as a caching mechanism to reduce the variance of Monte Carlo Partial Differential Equation solvers,
                     such as the Walk-on-Spheres algorithm<a href="http://www.cs.cmu.edu/~kmcrane/Projects/MonteCarloGeometryProcessing/index.html">[Sawhney and Crane 2020]</a>.
                     While these Monte Carlo PDE solvers have the merits of being unbiased and discretization-free,
                      their high variance often hinders real-time applications. 
                      On the other hand, neural networks can approximate the PDE solution, 
                      and evaluating these networks at inference time can be very fast. 
                      However, neural-network-based solutions may suffer from convergence difficulties and high bias. 
                      Our hybrid system aims to combine these two potentially complementary solutions by training a neural field to approximate the PDE solution using supervision from a WoS solver.
                      This neural field is then used as a cache in the WoS solver to reduce variance during inference.
                      We demonstrate that our neural field training procedure is better than the commonly used self-supervised objectives in the literature.
                      We also show that our hybrid solver exhibits lower variance than WoS with the same computational budget: 
                      it is significantly better for small compute budgets and provides smaller improvements for larger budgets,
                       reaching the same performance as WoS in the limit.
                </p>
            </div>
        </div>
        <div class='row mt-3 text-center center-block' style=" margin-left:auto; margin-right:auto; max-width:560px">
            <div class='col ml-1 mr-1' style="position: relative; width: 100%;height: 0;padding-bottom: 56%;">
                <iframe width="560" height="315" src="https://www.youtube.com/embed/TynncIBQXkk"
                        title="Neural Caches for Monte Carlo Partial Differential Equation Solver" frameborder="0"
                        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
            </div>
        </div>
    </div>
    <div class='col-md-15'>
        <p class='h4 font-weight-bold '>Introduction</p>
        <p>
            Solving PDEs without discretization is valuable in many graphics application. 
            Monte Carlo PDE solvers are un-biased but suffer from high variance.
            In contrast, Neural Fields-based solvers offer faster inference but often yield biased outcomes. 
            We propose to use neural field caches to reduce variance in Monte Carlo PDE solvers.     
        </p>

        <p class='h4 font-weight-bold '>Method</p>
        <img src="assets/method.png" class="img-fluid rounded mx-auto d-block">
        <p> 
            We want to build a hybrid solver to reduce the inference time for WoS by querying the neural field after a fixed compute budget.
            We achieve this hybrid solver in two steps. First, we use a WoS estimator to provide target data to supervise the neural field to approximate the PDE solution. 
            Once we obtain a neural field with a small enough error, we use a hybrid WoS solver that terminates the recursive call by querying the neural field. 
            Intuitively, this hybrid solver can lower the error of the neural field solution since it performs WoS-style random walks that can terminate at the boundary. 
            At the same time, it can achieve lower variance than the WoS estimator since it conducts shorter walks.
        </p>

    </div>
    <br>

    <br>
    <div class='col-md-15'>
        <p class='h4 font-weight-bold '>Equal Time Comparison </p>
        <div>
            <img src="assets/equal_time.png" class="img-fluid rounded mx-auto d-block">
            <p style="margin: 10px; margin-bottom: 4px;">
                We solve a variable coefficient screened Poisson equation with different domain shapes, including high-genus shapes like Sprocket (Row 2) and shapes with thin structures and sharp edges (Row 3). 
                We sample a 512x512 slice for each method and allocate 5 minutes of compute time to obtain the result. We can see that the hybrid solver can achieve more accurate results than both the self-supervised baseline (with high bias) and the WoS baseline (with high variance).
                The performance gap is larger when the PDE solution is high-frequency.
            </p>
        </div>
    </div>
    <br>
    <div class='col-md-15'>
        <p class='h4 font-weight-bold '>Equal Sample Comparison </p>

        <div>
            <img src="assets/equal_sample.png" class="img-fluid rounded mx-auto d-block">
            <p style="margin: 10px; margin-bottom: 4px;">
                <!-- Fig4 : Equal Sample Comparison -->
                L: we show the number of walks v.s. MSE curves. 
                Our method achieves lower MSE when the number of walks is limited.
                R: a qualitative comparison of different models at 100 walks per pixel.
            </p>
        </div>
    </div>

    <br>
    <div class='col-md-15'>
        <p class='h4 font-weight-bold '>Computation Time Breakdown </p>

        <div>
            <img src="assets/barplot.png" class="img-fluid rounded mx-auto d-block">
            <p style="margin: 10px; margin-bottom: 4px;">
                <!-- Fig4 : Equal Sample Comparison -->
                Computational time breakdown for WoS and our
                method. We report the time it took each of the methods to
                reach an MSE error of less than 5e-3. Our hybrid solver is
                faster than WoS when there are more test samples.
            </p>
        </div>
    </div>



    <div>
        <hr>
        <div class='row'>
            <div class='col-md-12 col-sm-12 col-xs-12'>
                <p class='h4 font-weight-bold'>Acknowledgements</p>
                <p style="margin: 10px; margin-bottom: 4px;">
                    This research was supported in part by the
                    National Science Foundation under grant 2212084, grant 2144117,
                    and by the RI-CAREER award 2046760. We want to thank Rohan
                    Sawhney and Wenqi Xian for their discussions.
                </p>
            </div>
        </div>
        <hr>
    </div>

</body>

</html>